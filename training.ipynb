{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Все импорты\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR, CosineAnnealingWarmRestarts\n",
        "from torch.optim import AdamW\n",
        "from torch_optimizer import Lamb\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "from torchvision.ops import StochasticDepth\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF  \n",
        "import random\n",
        "import numpy as np\n",
        "from torch.optim import SGD\n",
        "from torchvision.models import EfficientNet_B4_Weights, ResNet50_Weights\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Используемое устройство: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MoleDataset(Dataset):\n",
        "    def __init__(self, csv_file: str, img_dir: str, img_size: int = 256, is_train: bool = False):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.img_size = img_size\n",
        "        self.is_train = is_train\n",
        "        self.samples = [(self._find_image_path(row['isic_id']), row['benign_malignant']) \n",
        "                       for _, row in self.annotations.iterrows()]\n",
        "        self.image_cache = {} \n",
        "\n",
        "    def _find_image_path(self, img_id):\n",
        "        for ext in ('jpg', 'png', 'jpeg'):\n",
        "            path = os.path.join(self.img_dir, f\"{img_id}.{ext}\")\n",
        "            if os.path.exists(path):\n",
        "                return path\n",
        "        return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def _apply_augmentations(self, image: torch.Tensor) -> torch.Tensor:\n",
        "        if not self.is_train:\n",
        "            return image\n",
        "        \n",
        "        original_size = (self.img_size, self.img_size)\n",
        "        \n",
        "        # Геометрические ауг с сохранением размера\n",
        "        if random.random() > 0.5:\n",
        "            shift_x = random.uniform(-0.03, 0.03) * self.img_size\n",
        "            shift_y = random.uniform(-0.03, 0.03) * self.img_size\n",
        "            image = TF.affine(\n",
        "                image, \n",
        "                angle=0, \n",
        "                translate=(shift_x, shift_y), \n",
        "                scale=1.0, \n",
        "                shear=0\n",
        "            )\n",
        "            image = TF.resize(image, original_size)  \n",
        "        \n",
        "        if random.random() > 0.5:\n",
        "            angle = random.uniform(-10, 10)\n",
        "            image = TF.rotate(image, angle, fill=0)\n",
        "            image = TF.resize(image, original_size)\n",
        "        \n",
        "        # Зум\n",
        "        if random.random() > 0.5:\n",
        "            scale_factor = random.uniform(0.95, 1.05)\n",
        "            new_size = int(self.img_size * scale_factor)\n",
        "            image = TF.resize(image, (new_size, new_size))\n",
        "            image = TF.center_crop(image, original_size)  # Фиксируем размер\n",
        "\n",
        "        # Слегка меняют цвет\n",
        "        if random.random() > 0.5:\n",
        "            brightness_factor = random.uniform(0.95, 1.05)\n",
        "            contrast_factor = random.uniform(0.95, 1.05)\n",
        "            image = TF.adjust_brightness(image, brightness_factor)\n",
        "            image = TF.adjust_contrast(image, contrast_factor)\n",
        "\n",
        "        # Эффекты освещения\n",
        "        if random.random() > 0.7:\n",
        "            kernel_size = int(0.05 * self.img_size)\n",
        "            if kernel_size % 2 == 0:\n",
        "                kernel_size += 1\n",
        "            image = TF.gaussian_blur(image, kernel_size=[kernel_size, kernel_size], sigma=(0.1, 0.2))\n",
        "\n",
        "        # Cutput на фоне\n",
        "        if random.random() > 0.8:\n",
        "            h, w = image.shape[1], image.shape[2]\n",
        "            mask_size_h = int(random.uniform(0.02, 0.1) * h)\n",
        "            mask_size_w = int(random.uniform(0.02, 0.1) * w)\n",
        "            y = random.randint(0, h - mask_size_h)\n",
        "            x = random.randint(0, w - mask_size_w)\n",
        "            \n",
        "            center_x, center_y = w // 2, h // 2\n",
        "            if not (abs(x - center_x) < w//4 and abs(y - center_y) < h//4):\n",
        "                image[:, y:y+mask_size_h, x:x+mask_size_w] = 0\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, target = self.samples[idx]\n",
        "        \n",
        "        if img_path not in self.image_cache:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            # Используем torchvision.transforms.functional.resize вместо F.resize\n",
        "            img = TF.resize(img, (self.img_size, self.img_size))\n",
        "            img = TF.to_tensor(img)\n",
        "            self.image_cache[img_path] = img\n",
        "            \n",
        "        image = self.image_cache[img_path].clone()\n",
        "        \n",
        "        if self.is_train:\n",
        "            image = self._apply_augmentations(image)\n",
        "        \n",
        "        # Нормализация (после всех аугментаций)\n",
        "        image = TF.normalize(image, \n",
        "                          mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225])\n",
        "        \n",
        "        return image, torch.tensor(target, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "img_size = 224\n",
        "\n",
        "\n",
        "train_ds = MoleDataset(\n",
        "    csv_file='dataset_split/train_labels.csv',\n",
        "    img_dir='dataset_split/train', \n",
        "    img_size=img_size,\n",
        "    is_train=True\n",
        ")\n",
        "\n",
        "val_ds = MoleDataset(\n",
        "    csv_file='dataset_split/val_labels.csv', \n",
        "    img_dir='dataset_split/val', \n",
        "    img_size=img_size,\n",
        "    is_train=False\n",
        ")\n",
        "\n",
        "test_ds = MoleDataset(\n",
        "    csv_file='dataset_split/test_labels.csv',\n",
        "    img_dir='dataset_split/test',\n",
        "    img_size=img_size,\n",
        "    is_train=False\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ResNet50 PyTorch\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=1):  \n",
        "        super().__init__()\n",
        "        \n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(64, 3)\n",
        "        self.layer2 = self._make_layer(128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(512, 3, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * Bottleneck.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels,\n",
        "                          out_channels * Bottleneck.expansion,\n",
        "                          kernel_size=1,\n",
        "                          stride=stride,\n",
        "                          bias=False),\n",
        "                nn.BatchNorm2d(out_channels * Bottleneck.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(Bottleneck(self.in_channels, out_channels,\n",
        "                                 stride=stride,\n",
        "                                 downsample=downsample))\n",
        "        \n",
        "        self.in_channels = out_channels * Bottleneck.expansion\n",
        "        \n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(Bottleneck(self.in_channels,\n",
        "                                     out_channels))\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)   \n",
        "        x = torch.flatten(x, 1)   \n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)       \n",
        "               \n",
        "        return logits\n",
        "\n",
        "model = ResNet50().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EfficientNet B4\n",
        "model1 = models.efficientnet_b4(weights=EfficientNet_B4_Weights)\n",
        "model1.classifier = nn.Sequential(nn.Dropout(0.6), nn.Linear(1792, 1))\n",
        "model1 = model1.to(device)\n",
        "\n",
        "# Заморозка\n",
        "for param in model1.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model1.classifier.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ResNet50 \n",
        "model2 = models.resnet50(weights=ResNet50_Weights)\n",
        "\n",
        "# Замена классификатора \n",
        "num_features = model2.fc.in_features\n",
        "model2.fc = nn.Sequential(\n",
        "    nn.Dropout(0.8),  # Dropout для регуляризации\n",
        "    nn.Linear(num_features, 1)  # Один выход для бинарной классификации\n",
        ")\n",
        "\n",
        "model2 = model2.to(device)\n",
        "\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "for param in model2.fc.parameters():\n",
        "    param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ConvNeXt\n",
        "model3 = models.convnext_small(pretrained=True)\n",
        "\n",
        "for param in model3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Заменяем классификатор на бинарный\n",
        "num_features = model3.classifier[-1].in_features \n",
        "model3.classifier[-1] = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(num_features, 1),  # Выходной слой с 1 нейроном \n",
        "    nn.Flatten() \n",
        ")\n",
        "\n",
        "# Размораживаем классификатор\n",
        "for param in model3.classifier.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_metrics(epoch: int, **samples) -> None:\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(18, 10))\n",
        "    \n",
        "    for i, sample in enumerate(samples):\n",
        "        plt.subplot(ceil(len(samples) / 3), 3, i + 1)\n",
        "        plt.title(sample)\n",
        "        plt.yscale('log' if sample == 'Loss' else 'linear')\n",
        "        \n",
        "        for phase in ['train', 'val', 'test']:  # Теперь поддерживает test\n",
        "            if phase in samples[sample]:\n",
        "                plt.plot(range(len(samples[sample][phase])), \n",
        "                        samples[sample][phase], \n",
        "                        label=f\"{phase}\")\n",
        "        plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch} summary:\")\n",
        "    for name, grp in samples.items():\n",
        "        phases = []\n",
        "        for phase in ['train', 'val', 'test']:\n",
        "            if phase in grp and grp[phase]:\n",
        "                phases.append(f\"{phase}: {grp[phase][-1]:.4f}\")\n",
        "        print(f\"{name:<9} | {' | '.join(phases)}\")\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(all_labels, all_predictions):\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['Доброкачественные', 'Злокачественные'],\n",
        "                yticklabels=['Доброкачественные', 'Злокачественные'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingPipeline:\n",
        "    def __init__(self, model: nn.Module, train_loader: DataLoader,\n",
        "                 val_loader: DataLoader, test_loader: DataLoader, criterion: nn.Module,\n",
        "                 optimizer: optim.Optimizer, device: torch.device,\n",
        "                 scheduler=None,\n",
        "                 metrics_visualizer=show_metrics,\n",
        "                 scheduler_step_per_epoch: bool = True,\n",
        "                 checkpoint_dir=None,\n",
        "                 metric_average: str = 'macro',\n",
        "                 grad_accum_steps: int = 1,\n",
        "                 use_amp: bool = True,\n",
        "                 unfreeze_epoch: int = 20,\n",
        "                 early_stopping_patience: int = None, \n",
        "                 early_stopping_min_delta: float = 0.0): \n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.scheduler = scheduler\n",
        "        self.metrics_visualizer = metrics_visualizer\n",
        "        self.scheduler_step_per_epoch = scheduler_step_per_epoch\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.metric_average = metric_average\n",
        "        self.grad_accum_steps = grad_accum_steps\n",
        "        self.use_amp = use_amp\n",
        "        self.scaler = torch.amp.GradScaler(enabled=use_amp)\n",
        "        \n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "        self.early_stopping_min_delta = early_stopping_min_delta\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.epochs_without_improvement = 0\n",
        "\n",
        "        self.current_stage = 1  # 1 - только классификатор, 2 - все слои\n",
        "        self.unfreeze_epoch = unfreeze_epoch  # Эпоха для размораживания\n",
        "\n",
        "        if self.checkpoint_dir:\n",
        "            os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        self.metrics = {\n",
        "            'Loss': {'train': [], 'val': [], 'test': []},\n",
        "            'Accuracy': {'train': [], 'val': [], 'test': []},\n",
        "            'Precision': {'train': [], 'val': [], 'test': []},\n",
        "            'Recall': {'train': [], 'val': [], 'test': []},\n",
        "            'F1': {'train': [], 'val': [], 'test': []}\n",
        "        }\n",
        "\n",
        "    def unfreeze_backbone(self):\n",
        "        \"\"\"Размораживает backbone и добавляет новую группу параметров\"\"\"\n",
        "        print(\"\\nUnfreezing backbone layers...\")\n",
        "        \n",
        "        # 1. Размораживаем все параметры\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True\n",
        "        \n",
        "        # 2. Создаем новые группы параметров\n",
        "        head_params = []\n",
        "        backbone_params = []\n",
        "        \n",
        "        for name, param in self.model.named_parameters():\n",
        "            if 'classifier' in name or 'fc' in name:  # Параметры головы\n",
        "                head_params.append(param)\n",
        "            else:  # Параметры backbone\n",
        "                backbone_params.append(param)\n",
        "        \n",
        "        # 3. Заменяем оптимизатор\n",
        "        self.optimizer = torch.optim.AdamW([\n",
        "                {'params': [p for n,p in self.model.named_parameters() if 'classifier' in n or 'fc' in n], 'lr': 1e-6},\n",
        "                {'params': [p for n,p in self.model.named_parameters() if 'classifier' not in n and 'fc' not in n], 'lr': 1e-5}\n",
        "        ], weight_decay=0.05)\n",
        "        \n",
        "        self.current_stage = 2\n",
        "\n",
        "    def evaluate_test(self):\n",
        "        \"\"\"Отдельный метод для оценки на тестовом наборе\"\"\"\n",
        "        self.model.eval()\n",
        "        all_labels_list = []\n",
        "        all_outputs_list = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(self.test_loader):\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                \n",
        "                if outputs.dim() == 2 and outputs.shape[1] == 1:  \n",
        "                    outputs = outputs.squeeze(-1)\n",
        "                \n",
        "                all_outputs_list.append(outputs.cpu())\n",
        "                all_labels_list.append(labels.cpu())\n",
        "        \n",
        "        all_outputs = torch.cat(all_outputs_list)\n",
        "        all_labels = torch.cat(all_labels_list)\n",
        "        \n",
        "        # Вычисляем метрики\n",
        "        test_res = self._calculate_metrics(all_outputs, all_labels)\n",
        "        test_res['loss'] = self.criterion(all_outputs.to(self.device), \n",
        "                                        all_labels.float().to(self.device)).item()\n",
        "        \n",
        "        # Сохраняем метрики\n",
        "        for k, alias in (('loss', 'Loss'),\n",
        "                        ('accuracy', 'Accuracy'),\n",
        "                        ('precision', 'Precision'),\n",
        "                        ('recall', 'Recall'),\n",
        "                        ('f1', 'F1')):\n",
        "            self.metrics[alias]['test'].append(test_res[k])\n",
        "        \n",
        "        # Вычисляем предсказания для confusion matrix\n",
        "        predictions = (torch.sigmoid(all_outputs) > 0.5).long()\n",
        "        if len(all_outputs.shape) > 1 and all_outputs.shape[1] == 1:\n",
        "            predictions = predictions.squeeze(1)\n",
        "        \n",
        "        # Отображаем confusion matrix\n",
        "        print(\"\\n=== Test Confusion Matrix ===\")\n",
        "        plot_confusion_matrix(all_labels.numpy(), predictions.numpy())\n",
        "        \n",
        "        return test_res\n",
        "\n",
        "    def _check_early_stopping(self, val_loss: float) -> bool:\n",
        "        \"\"\"Проверяет, нужно ли остановить обучение.\"\"\"\n",
        "        if self.early_stopping_patience is None:\n",
        "            return False\n",
        "            \n",
        "        improved = (self.best_val_loss - val_loss) > self.early_stopping_min_delta\n",
        "        \n",
        "        if improved:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.epochs_without_improvement = 0\n",
        "        else:\n",
        "            self.epochs_without_improvement += 1\n",
        "            if self.epochs_without_improvement >= self.early_stopping_patience:\n",
        "                print(f\"\\nEarly stopping triggered! No improvement for {self.early_stopping_patience} epochs.\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _calculate_metrics(self, all_outputs: torch.Tensor, all_labels: torch.Tensor):\n",
        "        if all_labels.numel() == 0:\n",
        "            return {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
        "        \n",
        "        predicted = (torch.sigmoid(all_outputs) > 0.5).long()\n",
        "        if len(all_outputs.shape) > 1 and all_outputs.shape[1] == 1:\n",
        "            predicted = predicted.squeeze(1)\n",
        "        \n",
        "        if all_outputs.dim() > 1:\n",
        "            if all_outputs.size(1) == 1:  # \n",
        "                all_outputs = all_outputs.squeeze(-1)\n",
        "            else:  \n",
        "                all_outputs = torch.argmax(all_outputs, dim=1)\n",
        "\n",
        "        labels_np = all_labels.cpu().numpy()\n",
        "        predicted_np = predicted.cpu().numpy()\n",
        "        \n",
        "        accuracy = (predicted == all_labels).float().mean().item()\n",
        "        precision = precision_score(labels_np, predicted_np, average='binary', zero_division=0)\n",
        "        recall = recall_score(labels_np, predicted_np, average='binary', zero_division=0)\n",
        "        f1 = f1_score(labels_np, predicted_np, average='binary', zero_division=0)\n",
        "        \n",
        "        return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "    def _run_epoch(self, phase: str):\n",
        "        is_train = phase == 'train'\n",
        "        if phase == 'train':\n",
        "            self.model.train()\n",
        "            loader = self.train_loader\n",
        "        elif phase == 'val':\n",
        "            self.model.eval()\n",
        "            loader = self.val_loader\n",
        "        else:  # test\n",
        "            self.model.eval()\n",
        "            loader = self.test_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        all_labels_list = []\n",
        "        all_outputs_list = []\n",
        "        processed_samples = 0\n",
        "        counter = 0\n",
        "\n",
        "        context = torch.enable_grad() if is_train else torch.no_grad()\n",
        "        with context:\n",
        "            for batch_idx, (inputs, labels) in enumerate(tqdm(loader)):\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "                with torch.amp.autocast(device_type='cuda', enabled=self.use_amp and is_train):\n",
        "                    outputs = self.model(inputs)\n",
        "                    \n",
        "                    if outputs.dim() == 2 and outputs.shape[1] == 1:  \n",
        "                        outputs = outputs.squeeze(-1) \n",
        "                    elif outputs.dim() > 2:\n",
        "                        outputs = outputs.view(outputs.size(0), -1)  \n",
        "                        if outputs.shape[1] == 1:\n",
        "                            outputs = outputs.squeeze(-1)\n",
        "                    \n",
        "                    loss = self.criterion(outputs, labels.float())\n",
        "                    \n",
        "                    if is_train:\n",
        "                        loss = loss / self.grad_accum_steps\n",
        "\n",
        "                if is_train:\n",
        "                    self.scaler.scale(loss).backward()\n",
        "\n",
        "                    if (batch_idx + 1) % self.grad_accum_steps == 0 or (batch_idx + 1) == len(loader):\n",
        "                        self.scaler.step(self.optimizer)\n",
        "                        self.scaler.update()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "                batch_size = inputs.size(0)\n",
        "                running_loss += loss.item() * batch_size * (self.grad_accum_steps if is_train else 1)\n",
        "                processed_samples += batch_size\n",
        "\n",
        "                all_outputs_list.append(outputs.detach().cpu())\n",
        "                all_labels_list.append(labels.detach().cpu())\n",
        "\n",
        "        all_outputs_tensor = torch.cat(all_outputs_list, dim=0) if all_outputs_list else torch.empty(0)\n",
        "        all_labels_tensor = torch.cat(all_labels_list, dim=0) if all_labels_list else torch.empty(0)\n",
        "\n",
        "        epoch_loss = running_loss / processed_samples if processed_samples > 0 else 0.0\n",
        "        epoch_metrics = self._calculate_metrics(all_outputs_tensor, all_labels_tensor)\n",
        "\n",
        "        return {'loss': epoch_loss, **epoch_metrics}\n",
        "\n",
        "    def _save_checkpoint(self, epoch: int, val_loss: float):\n",
        "        if not self.checkpoint_dir:\n",
        "            return\n",
        "\n",
        "        checkpoint_path = os.path.join(self.checkpoint_dir, f'model_epoch_{epoch}.pth')\n",
        "        state = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'scaler_state_dict': self.scaler.state_dict() if self.use_amp else None,\n",
        "        }\n",
        "        if self.scheduler:\n",
        "            state['scheduler_state_dict'] = self.scheduler.state_dict()\n",
        "\n",
        "        torch.save(state, checkpoint_path)\n",
        "\n",
        "    def run_training(self, num_epochs: int):\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            if epoch == self.unfreeze_epoch and self.current_stage == 1:\n",
        "                self.unfreeze_backbone()\n",
        "            train_res = self._run_epoch('train')\n",
        "            val_res = self._run_epoch('val')\n",
        "\n",
        "            for k, alias in (('loss', 'Loss'),\n",
        "                            ('accuracy', 'Accuracy'),\n",
        "                            ('precision', 'Precision'),\n",
        "                            ('recall', 'Recall'),\n",
        "                            ('f1', 'F1')):\n",
        "                self.metrics[alias]['train'].append(train_res[k])\n",
        "                self.metrics[alias]['val'].append(val_res[k])\n",
        "\n",
        "            if self.metrics_visualizer:\n",
        "                filtered_metrics = {\n",
        "                    k: {'train': v['train'], 'val': v['val']} \n",
        "                    for k, v in self.metrics.items()\n",
        "                }\n",
        "                self.metrics_visualizer(epoch, **filtered_metrics)\n",
        "                print('Current LR:', self.optimizer.param_groups[0]['lr'])\n",
        "\n",
        "            if self._check_early_stopping(val_res['loss']):\n",
        "                break\n",
        "\n",
        "            if self.scheduler:\n",
        "                if self.scheduler_step_per_epoch and not isinstance(\n",
        "                        self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    self.scheduler.step()\n",
        "                elif isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    self.scheduler.step(val_res['loss'])\n",
        "\n",
        "            if self.checkpoint_dir:\n",
        "                self._save_checkpoint(epoch, val_res['loss'])\n",
        "\n",
        "        #test_res = self._run_epoch('test')\n",
        "        test_res = self.evaluate_test() \n",
        "        print(\"\\n=== Final Test Evaluation ===\")\n",
        "        for metric, value in test_res.items():\n",
        "            print(f\"{metric.capitalize():<10}: {value:.4f}\")\n",
        "            self.metrics[metric.capitalize()]['test'].append(value)  \n",
        "\n",
        "        print(\"Training finished.\")\n",
        "        return self.metrics\n",
        "    \n",
        "    def evaluate_ensemble(self, model1, model2, model3):\n",
        "        \"\"\"Оценка ансамбля на тестовой выборке + метрики.\"\"\"\n",
        "        ensemble = HardVotingEnsemble(model1, model2, model3, self.device)\n",
        "        preds, labels = ensemble.predict(self.test_loader)\n",
        "        \n",
        "        # Вычисляем метрики\n",
        "        metrics = {\n",
        "            \"accuracy\": accuracy_score(labels, preds),\n",
        "            \"precision\": precision_score(labels, preds, zero_division=0),\n",
        "            \"recall\": recall_score(labels, preds, zero_division=0),\n",
        "            \"f1\": f1_score(labels, preds, zero_division=0),\n",
        "        }\n",
        "        \n",
        "        # Confusion Matrix\n",
        "        self._plot_confusion_matrix(labels.numpy(), preds.numpy())\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def _plot_confusion_matrix(self, y_true, y_pred):\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(\n",
        "            cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Benign (0)\", \"Malignant (1)\"],\n",
        "            yticklabels=[\"Benign (0)\", \"Malignant (1)\"]\n",
        "        )\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "        plt.title(\"Ensemble Confusion Matrix\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load('tested_models/checkpoints_ConvNeXt_small/ConvNeXt.pth')['model_state_dict']\n",
        "model.load_state_dict(checkpoint) # Чтобы загрузить состояние"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FocalLoss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)  \n",
        "        focal_loss = self.alpha * (1 - pt)**self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model # Чтобы посмотреть архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 0 # Отдельно задать число эпох"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(\n",
        "    model1.parameters(),  # Только размороженные параметры\n",
        "    lr=1e-6,\n",
        "    weight_decay=0.05\n",
        ")\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.37]).to(device))\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer=optimizer,\n",
        "    T_max=30,\n",
        "    eta_min=1e-6\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = TrainingPipeline(model=model1,\n",
        "                            train_loader=train_loader,\n",
        "                            val_loader=val_loader,\n",
        "                            test_loader=test_loader,\n",
        "                            criterion=criterion,\n",
        "                            optimizer=optimizer,\n",
        "                            device=device,\n",
        "                            scheduler=scheduler,\n",
        "                            metrics_visualizer=show_metrics,\n",
        "                            scheduler_step_per_epoch=True,\n",
        "                            grad_accum_steps=2,\n",
        "                            use_amp=True,\n",
        "                            unfreeze_epoch=70,\n",
        "                            early_stopping_patience=50,  \n",
        "                            early_stopping_min_delta=0.00001, \n",
        "                            checkpoint_dir='tested_models/checkpoints_ConvNeXt_small')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_metrics = pipeline.run_training(num_epochs=num_epochs)\n",
        "print(final_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HardVotingEnsemble:\n",
        "    def __init__(self, model1, model2, model3, device=\"cuda\"):\n",
        "        self.models = [model1.to(device), model2.to(device), model3.to(device)]\n",
        "        self.device = device\n",
        "        \n",
        "    def predict(self, dataloader):\n",
        "        \"\"\"Предсказывает классы для всей тестовой выборки.\"\"\"\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(dataloader, desc=\"Ensemble Prediction\"):\n",
        "                inputs = inputs.to(self.device)\n",
        "                batch_preds = []\n",
        "                \n",
        "                # Получаем предсказания от каждой модели\n",
        "                for model in self.models:\n",
        "                    model.eval()\n",
        "                    outputs = model(inputs)\n",
        "                    preds = (torch.sigmoid(outputs) > 0.5).int().cpu()\n",
        "                    batch_preds.append(preds)\n",
        "                \n",
        "                # Применяем Hard Voting: 0 только если все три модели дали 0\n",
        "                batch_preds = torch.stack(batch_preds)\n",
        "                ensemble_preds = (batch_preds.sum(dim=0) > 0).int()  # 1 если хотя бы одна модель дала 1\n",
        "                \n",
        "                all_preds.append(ensemble_preds)\n",
        "                all_labels.append(labels)\n",
        "        \n",
        "        return torch.cat(all_preds), torch.cat(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load('tested_models/checkpoints_ENetb4/ENet.pth')['model_state_dict']\n",
        "model1.load_state_dict(checkpoint) # Чтобы загрузить состояние\n",
        "\n",
        "\n",
        "checkpoint = torch.load('tested_models/checkpoints_ResNet50/ResNet.pth')['model_state_dict']\n",
        "model2.load_state_dict(checkpoint) # Чтобы загрузить состояние\n",
        "\n",
        "checkpoint = torch.load('tested_models/checkpoints_ConvNeXt_small/ConvNeXt.pth')['model_state_dict']\n",
        "model3.load_state_dict(checkpoint) # Чтобы загрузить состояние\n",
        "# Оцениваем ансамбль\n",
        "ensemble_metrics = pipeline.evaluate_ensemble(model1, model2, model3)\n",
        "\n",
        "print(\"\\n=== Ensemble Test Metrics ===\")\n",
        "for name, value in ensemble_metrics.items():\n",
        "    print(f\"{name.capitalize():<10}: {value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
